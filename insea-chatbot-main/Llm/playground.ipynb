{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding from hugginface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "docsearch = OpenSearchVectorSearch(\n",
    "    opensearch_url = 'https://localhost:9200',\n",
    "    embedding_function=embeddings,\n",
    "    # index_name='nextjs-video',\n",
    "    index_name=None,\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = ('admin','admin'),\n",
    "    use_ssl = False,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# transcript = YoutubeLoader('lG7Uxts9SXs&t=2373s').load()\n",
    "transcript = YoutubeLoader('H0vhkoXljq0').load()\n",
    "docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "docsearch.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docsearch.similarity_search(\"project\", k=5)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "\n",
    "\n",
    "def extract_metadata(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"id\"] = record['url']\n",
    "    return metadata\n",
    "\n",
    "JSON_PATH = './output.json'\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=JSON_PATH,\n",
    "    jq_schema='.commit_history[]',\n",
    "    text_content=False,\n",
    "    metadata_func=extract_metadata\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms.together import Together\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TOGETHER_API = os.getenv('TOGETHER_API')\n",
    "\n",
    "model = Together(together_api_key=TOGETHER_API, \n",
    "                 max_tokens=500,\n",
    "                 model='togethercomputer/llama-2-13b-chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from palmLLM import PalmLLM\n",
    "\n",
    "\n",
    "model = PalmLLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \" \".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    " \n",
    "prompt = PromptTemplate(input_variables=['question', 'docs'],\n",
    "                            template='''\n",
    "                            You are a helpful Youtube assistant that can answer questions about videos based on the video's transcript.\n",
    "                            \n",
    "                            Answer the following question : \"{question}\"\n",
    "                            Based on the following transcript : \"{docs}\"\n",
    "                            \n",
    "                            Only use the factual information within the transcript.\n",
    "                            ''')\n",
    "\n",
    "chain = (\n",
    "        {\"question\": RunnablePassthrough(), \"docs\": retriever | format_docs} \n",
    "        | prompt \n",
    "        | model \n",
    "        | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how many videos are there?\"\n",
    "\n",
    "for i in chain.stream(question):\n",
    "    print(i, end='\\n', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Answer the following question : {question}\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful Youtube assistant that can answer questions about videos based on the video's transcript.\n",
    "\n",
    "Based on the following transcript : \"{docs}\"\n",
    "\n",
    "Answer the user question \"{question}\".\n",
    "\n",
    "Only use the factual information within the transcript.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['docs', 'question'], template=template)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {'docs': retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what's the projects discussed?\"\n",
    "# chain.invoke(question)\n",
    "for i in chain.stream(question):\n",
    "    print(i, end='\\n', flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test OpenSearch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "\n",
    "auth = ('admin', 'admin') # For testing only. Don't store credentials in code.\n",
    "client = OpenSearch(\n",
    "    hosts = 'https://localhost:9200',\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = auth,\n",
    "    use_ssl = False,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search(index=\"langchain-video\")['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_by_query(index=\"langchain-video\", body={\"query\": {\"match_all\": {}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from operator import itemgetter\n",
    "# Answer the following question : {question}\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful Youtube assistant that can answer questions about videos based on the video's transcript.\n",
    "\n",
    "Based on the following transcript : \"{docs}\"\n",
    "\n",
    "Answer the user question \"{question}\".\n",
    "\n",
    "Only use the factual information within the transcript.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['docs', 'question'], template=template)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {'docs': retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "chain = {'memory' : RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"), 'docs': retriever | format_docs, \"question\": RunnablePassthrough()} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Hello'\n",
    "\n",
    "inputs = {\"question\": question}\n",
    "\n",
    "while question != '':\n",
    "    question = input()\n",
    "    # resp = qa(question)\n",
    "    resp = chain.invoke(question)\n",
    "    print(f'{resp}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
